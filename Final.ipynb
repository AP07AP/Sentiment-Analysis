{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c51ab9-1450-42c1-a8d3-b831e597d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import spacy\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b097390-10d4-4150-bb1b-b3ed7009ac5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91867\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91867\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91867\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "860933ae-a56d-4a8a-96d9-daf2cd34fd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load the data (Ensure your dataframe is loaded into df)\n",
    "# Example: df = pd.read_csv('path_to_file.csv')\n",
    "df=pd.read_csv(\"IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdc5e03d-9dd6-4770-b650-1edc089d0701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataset: 50000\n",
      "Number of duplicate rows: 418\n",
      "Missing values in 'review' column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Initial Data Inspection\n",
    "print(f\"Number of rows in dataset: {len(df)}\")\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Missing values in 'review' column: {df['review'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "445d2bd3-4fe3-4149-b1ba-c0a0718499cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Drop missing or duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna(subset=['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62e0bdfd-2c3a-4ee0-b544-add996e26214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "Missing values in 'review' column: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Missing values in 'review' column: {df['review'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdd57dde-0c27-4a22-abf5-eab41ff09082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiseremoval_text(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")  # Remove HTML tags\n",
    "    text = soup.get_text()\n",
    "    text = re.sub(r'\\[|\\]', '', text)  # Remove square brackets only\n",
    "    text = re.sub(r'\\[[^]]*\\]', '', text)  # Remove text in square brackets \n",
    "    text = re.sub(r'\\(|\\)', '', text)  # For round braces ()\n",
    "    text = re.sub(r'\\{|\\}', '', text)  # For curly braces {}\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d919a25-f172-4773-ba93-1e73a3dc1aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91867\\AppData\\Local\\Temp\\ipykernel_25572\\931013351.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")  # Remove HTML tags\n"
     ]
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(noiseremoval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25c3ec30-d788-4d9c-8eb4-ed609ada5e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. The filming tec...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23628a7b-bc2d-47b7-9553-a8fd46dbf20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy Jake thinks there's a zombie in his closet & his parents are fighting all the time.This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d27b3a19-61fa-42ab-833f-772270f7b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Convert text to lowercase\n",
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8678cf0-610f-4cde-b040-d0001f5a2156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Remove special characters and numbers\n",
    "df['review'] = df['review'].str.replace(r'[^a-zA-Z\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38e9b8af-1132-4ca1-8635-09d465f958af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basically theres a family where a little boy jake thinks theres a zombie in his closet  his parents are fighting all the timethis movie is slower than a soap opera and suddenly jake decides to become rambo and kill the zombieok first of all when youre going to make a film you must decide if its a thriller or a drama as a drama the movie is watchable parents are divorcing  arguing like in real life and then we have jake with his closet which totally ruins all the film i expected to see a boogeyman similar movie and instead i watched a drama with some meaningless thriller spots out of  just for the well playing parents  descent dialogs as for the shots with jake just ignore them'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8dd2cb8a-f0c4-4997-82c4-239d16ec4286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Tokenization and Stopword Removal\n",
    "stop_wr = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7546e22b-a329-4b38-a58d-50d04d8403dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_stopwords(text):\n",
    "    tokenizers = ToktokTokenizer()\n",
    "    tokens = tokenizers.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens if token.lower() not in stop_wr]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "816d7346-82cd-4aff-85cc-25053089de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(removing_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83d201a1-9a59-49cf-b7b9-2d5600f6db4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basically theres family little boy jake thinks theres zombie closet parents fighting timethis movie slower soap opera suddenly jake decides become rambo kill zombieok first youre going make film must decide thriller drama drama movie watchable parents divorcing arguing like real life jake closet totally ruins film expected see boogeyman similar movie instead watched drama meaningless thriller spots well playing parents descent dialogs shots jake ignore'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "668e304a-3a42-4c16-a11d-bed432548cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Lemmatization (Better than Stemming for meaningful text)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(word) for word in tokens])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32087cd6-f556-4940-b188-4ca4140fe81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b6a7bfd-7bf8-4bda-a62e-e489e2fc3faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basically there family little boy jake think there zombie closet parent fighting timethis movie slower soap opera suddenly jake decides become rambo kill zombieok first youre going make film must decide thriller drama drama movie watchable parent divorcing arguing like real life jake closet totally ruin film expected see boogeyman similar movie instead watched drama meaningless thriller spot well playing parent descent dialog shot jake ignore'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "010038f7-5fb4-423c-a1ea-50a2d4a8f3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after preprocessing: 49582\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Final Inspection and Save Processed Data\n",
    "print(f\"Number of rows after preprocessing: {len(df)}\")\n",
    "df.to_csv('cleaned_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7113e1f-8972-49b9-b232-573b4b99a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset \n",
    "#train dataset\n",
    "train_reviews_data=df.review[:30000]\n",
    "#test dataset\n",
    "test_reviews_data=df.review[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50f2ba90-a1bd-4383-acf2-bd368cc432b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train shape: (30000, 5475474)\n",
      "BOW_cv_test shape: (19582, 5475474)\n"
     ]
    }
   ],
   "source": [
    "# Bag of Words (BoW) with CountVectorizer\n",
    "cv = CountVectorizer(min_df=1, max_df=0.9, binary=False, ngram_range=(1, 3))\n",
    "\n",
    "# Fit and transform the train reviews\n",
    "cv_train = cv.fit_transform(train_reviews_data)\n",
    "\n",
    "# Transform the test reviews\n",
    "cv_test = cv.transform(test_reviews_data)\n",
    "\n",
    "# Print the shapes of the transformed datasets\n",
    "print('BOW_cv_train shape:', cv_train.shape)\n",
    "print('BOW_cv_test shape:', cv_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14a54a3a-42e7-4861-a1ab-71ed5cf7ce8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa' 'aa antic' 'aa antic random' ... 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz'\n",
      " 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz ooops'\n",
      " 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz ooops sorry']\n"
     ]
    }
   ],
   "source": [
    "# To get feature names (vocabulary words)\n",
    "vocab = cv.get_feature_names_out()\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6738461a-7e95-4dcc-af24-e5dbef31382c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5475474"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2610bc0-28ce-47dd-a5cf-392bad9e013a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'without doubt offensive chick flick seen year ever writing characterization riddled stereotype film verge parody walking theater hour five minute disaster subjected following theme baby solve problem performer type miserable mess musician cant good mother unless toss dream conventional lifestyle waste talented cast greatlooking set costume natasha richardson told toni collette unless life mainstream life shell end shudder alone felt queasy cant believe movie made theatrical release sort fare one expects woman cable channel always pas right channelsurfing female part film target audience boy evening miss target'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][15885]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e67aed3-c2ae-4450-b6e8-76c424c77281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yawn oz oh um excuse sorry fell asleep mooment oh yes projected man yes z ooops sorry yes projected man well british scifi yawnfest nothing orangeheaded guy project laser get touch death last vanishes end actually film even interesting dull droning starchy stiff backbreakingly boring projected man solid minute nothing starring nobody dull dishwater dull doorknob dust dull ethan hawke talking really dull people wait respect dull cousin across puddle moocow proper review projected manz'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][15923]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8fde6775-3cf1-4588-b9f3-cde4351b3ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "15923  yaaaaaaaaaaaaaawwwwwwwwwwwwwwwwwnnnnnnnnnnnnn ...  negative\n"
     ]
    }
   ],
   "source": [
    "# Check for rows containing \"zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz\"\n",
    "noisy_rows = df[df['review'].str.contains('zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz', na=False)]\n",
    "print(noisy_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "70617ad4-9dec-49a8-9df0-38d3f64e4f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_repeated_chars(text):\n",
    "    return re.sub(r'(.)\\1{4,}', r'\\1', text)\n",
    "\n",
    "# Apply to the review column\n",
    "df['review'] = df['review'].apply(clean_repeated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2477204-58d7-40cb-bd5e-d65cdcf393a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [review, sentiment]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for rows containing \"zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz\"\n",
    "noisy_rows = df[df['review'].str.contains('zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz', na=False)]\n",
    "print(noisy_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d923c5b-81fd-49c8-ae4f-079f81ab7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset \n",
    "#train dataset\n",
    "train_reviews_data=df.review[:30000]\n",
    "#test dataset\n",
    "test_reviews_data=df.review[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ba2b4d2e-313a-4096-96cc-9e4e58f675b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Vocabulary: 5475189 terms\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=1, max_df=0.9, ngram_range=(1, 3))\n",
    "cv_train = cv.fit_transform(train_reviews_data)\n",
    "vocab = cv.get_feature_names_out()\n",
    "print(f\"Cleaned Vocabulary: {len(vocab)} terms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "39cbacbe-913e-45b1-8eba-2e6736c43ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train shape: (30000, 5475189)\n",
      "BOW_cv_test shape: (19582, 5475189)\n"
     ]
    }
   ],
   "source": [
    "# Transform the test reviews\n",
    "cv_test = cv.transform(test_reviews_data)\n",
    "\n",
    "# Print the shapes of the transformed datasets\n",
    "print('BOW_cv_train shape:', cv_train.shape)\n",
    "print('BOW_cv_test shape:', cv_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95d2e85a-a6bd-4226-9931-bfa5b08f1187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa' 'aa antic' 'aa antic random' ... 'zzzzip' 'zzzzip message'\n",
      " 'zzzzip message coming']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ae016e1-d7a1-416e-8613-10ce709196b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa' 'aa antic' 'aa antic random' 'aa cultrehab' 'aa cultrehab many'\n",
      " 'aa date' 'aa date aa' 'aa doctor' 'aa doctor miraculously' 'aa group'\n",
      " 'aa group nobody' 'aa jaega' 'aa jaega every' 'aa meeting'\n",
      " 'aa meeting get' 'aa meeting interesting' 'aa meri' 'aa meri life'\n",
      " 'aa milne' 'aa milne book']\n"
     ]
    }
   ],
   "source": [
    "print(vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f1517d5-89cd-41a2-a504-137052ac96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_repeated_chars(text):\n",
    "    # Replace 4 or more consecutive repeating characters with just one occurrence\n",
    "    return re.sub(r'(.)\\1{3,}', r'\\1', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c51cd5b7-edfd-4616-bb6e-08fcd0b9d601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zip'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_repeated_chars('zzzzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0114dde2-8467-401d-9585-e814cf2afd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to the review column\n",
    "df['review'] = df['review'].apply(clean_repeated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b344316d-5b72-4e44-b48a-c7fafd57cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset \n",
    "#train dataset\n",
    "train_reviews_data=df.review[:30000]\n",
    "#test dataset\n",
    "test_reviews_data=df.review[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe02680c-b968-4278-a998-8ca40ff23dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (30000, 4984704)\n",
      "BOW_cv_test: (19582, 4984704)\n"
     ]
    }
   ],
   "source": [
    "# Bow\n",
    "#Count vectorizer for bag of words\n",
    "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "cv_train=cv.fit_transform(train_reviews_data)\n",
    "#transformed test reviews\n",
    "cv_test=cv.transform(test_reviews_data)\n",
    "print('BOW_cv_train:',cv_train.shape)\n",
    "print('BOW_cv_test:',cv_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ad54e60-af72-41ff-9b65-6dd09709d443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa antic' 'aa antic random' 'aa cultrehab' 'aa cultrehab many' 'aa date'\n",
      " 'aa date aa' 'aa doctor' 'aa doctor miraculously' 'aa group'\n",
      " 'aa group nobody' 'aa jaega' 'aa jaega every' 'aa meeting'\n",
      " 'aa meeting get' 'aa meeting interesting' 'aa meri' 'aa meri life'\n",
      " 'aa milne' 'aa milne book' 'aa mindless']\n"
     ]
    }
   ],
   "source": [
    "# To get feature names (vocabulary words)\n",
    "vocab = cv.get_feature_names_out()\n",
    "print(vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ec71943d-1a9e-409f-9458-509cec4ab98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1        positive\n",
       "2        positive\n",
       "3        negative\n",
       "4        positive\n",
       "           ...   \n",
       "49995    positive\n",
       "49996    negative\n",
       "49997    negative\n",
       "49998    negative\n",
       "49999    negative\n",
       "Name: sentiment, Length: 49582, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1786bc4e-b8ca-46ce-9165-515d6c90e4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49582, 1)\n"
     ]
    }
   ],
   "source": [
    "# label encoding\n",
    "#labeling the sentient data\n",
    "label=LabelBinarizer()\n",
    "#transformed sentiment data\n",
    "sentiment_data=label.fit_transform(df['sentiment'])\n",
    "print(sentiment_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b550cc26-9189-4adb-8e8b-bdeb556b62ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1        positive\n",
       "2        positive\n",
       "3        negative\n",
       "4        positive\n",
       "           ...   \n",
       "49995    positive\n",
       "49996    negative\n",
       "49997    negative\n",
       "49998    negative\n",
       "49999    negative\n",
       "Name: sentiment, Length: 49582, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b9c81b75-4430-4fef-9282-1dc4429b80ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be4ef292-9752-41f8-9cf1-43703d821e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91867\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)  # max_iter set to ensure convergence\n",
    "model.fit(cv_train, sentiment_data[:30000])  # Fit on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e009366e-69f3-4fea-9ebd-cbf7517cf75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Make predictions on the test set\n",
    "y_pred = model.predict(cv_test)  # Predict on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f62e07f1-2a9e-4750-a962-fc1b3ec9ccfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ab6fa01a-dc68-4aa0-b433-593b56ed9d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6d0a66ac-a80b-46e1-b2bd-7ad7a6f498dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.7113675824737004\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.59      0.67      9750\n",
      "           1       0.67      0.83      0.74      9832\n",
      "\n",
      "    accuracy                           0.71     19582\n",
      "   macro avg       0.72      0.71      0.71     19582\n",
      "weighted avg       0.72      0.71      0.71     19582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Evaluate the model\n",
    "print(\"Accuracy on Test Data:\", accuracy_score(sentiment_data[30000:], y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(sentiment_data[30000:], y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "61745be6-fe59-4852-b246-0e126c9ba340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "932d1611-2631-4b7c-b99e-80e872197895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (30000, 4984704)\n",
      "Tfidf_test: (19582, 4984704)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Tfidf Vectorization\n",
    "tf = TfidfVectorizer(min_df=0, max_df=1, use_idf=True, ngram_range=(1, 3))\n",
    "\n",
    "# Fit and transform the training data\n",
    "tf_train = tf.fit_transform(train_reviews_data)\n",
    "\n",
    "# Transform the test data (using the same vocabulary as train data)\n",
    "tf_test = tf.transform(test_reviews_data)\n",
    "\n",
    "# Display the shapes of the resulting sparse matrices\n",
    "print('Tfidf_train:', tf_train.shape)\n",
    "print('Tfidf_test:', tf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b45e6ba7-ebf8-4588-a22a-6d93a446d6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.7304667551833316\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.68      0.71      9750\n",
      "    positive       0.71      0.79      0.75      9832\n",
      "\n",
      "    accuracy                           0.73     19582\n",
      "   macro avg       0.73      0.73      0.73     19582\n",
      "weighted avg       0.73      0.73      0.73     19582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the Logistic Regression model using TF-IDF features\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(tf_train, train_data)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(tf_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy on Test Data:\", accuracy_score(test_data, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(test_data, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "deb9bece-7520-4e8b-8027-315e6fe917cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp311-cp311-win_amd64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\91867\\appdata\\roaming\\python\\python311\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\91867\\appdata\\roaming\\python\\python311\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\91867\\appdata\\roaming\\python\\python311\\site-packages (from gensim) (6.4.0)\n",
      "Downloading gensim-4.3.3-cp311-cp311-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.3/24.0 MB 9.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 3.9/24.0 MB 10.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 5.8/24.0 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 7.9/24.0 MB 10.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.4/24.0 MB 9.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.3/24.0 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.7/24.0 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 17.0/24.0 MB 10.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.7/24.0 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.3/24.0 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.9/24.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.9/24.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 9.2 MB/s eta 0:00:00\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3d954816-393d-4f4e-90b9-d09e41f38c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91867\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenize the text into words\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())  # Tokenize and convert to lowercase\n",
    "    return tokens\n",
    "\n",
    "# Apply tokenization on your reviews\n",
    "train_reviews_tokenized = [tokenize_text(review) for review in train_reviews_data]\n",
    "test_reviews_tokenized = [tokenize_text(review) for review in test_reviews_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "686dbfc7-451e-4480-a31e-866e33d1c2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.37362945 -0.67946154 -0.683327   -0.6508947  -0.92286175 -0.164238\n",
      "  0.76383626  0.638367   -0.3445068  -0.78728276 -0.00953209 -0.9993129\n",
      "  0.6226789  -2.2938333  -0.09167035  0.48447752 -0.17421237 -1.2971038\n",
      "  1.0137086   0.86710966 -0.82268524 -1.5235339   0.3954865  -0.15045083\n",
      " -2.148113    0.9219072   0.6612612  -0.266566   -0.9441023   2.5858605\n",
      "  1.6344482  -1.5460397   0.12406377 -0.5407781  -2.3851876   3.2166762\n",
      " -0.5359616  -0.33352605 -0.35682857 -1.7206808   0.9039067  -0.475326\n",
      " -0.9606173  -0.16273151  0.01334623  0.9417418  -0.9761025  -0.48772833\n",
      "  0.5097566  -0.90270245 -0.6473836  -3.6516194  -0.09869592 -1.9420846\n",
      "  0.56001264  1.7953666   1.9667585  -0.5688923   0.34527823  0.6907538\n",
      "  0.9965901  -1.5100789   2.2194633  -0.4867459  -1.7606742   1.0063808\n",
      " -0.32091036  2.7800393  -0.36371216  0.8606768   3.364578   -1.5193684\n",
      "  0.6045992   0.7553582   0.78659856  1.797509    0.05035514 -0.04664953\n",
      " -1.3291411   0.89079964 -0.644129   -2.1624558  -2.1079123   2.0044675\n",
      "  0.68548703 -1.5781955  -0.23405218  0.19811311 -0.31647593 -3.0549548\n",
      "  2.5109653   1.2840037  -0.9811032   1.6539973   0.34455135  1.4155296\n",
      " -0.10282804 -1.8978573   1.4268388  -1.1074795 ]\n"
     ]
    }
   ],
   "source": [
    "# Train Word2Vec model (Skip-gram or CBOW)\n",
    "model = Word2Vec(sentences=train_reviews_tokenized, vector_size=100, window=5, min_count=1, sg=0)  # sg=0 for CBOW, sg=1 for Skip-gram\n",
    "\n",
    "# Save the model for later use\n",
    "model.save(\"word2vec_model\")\n",
    "\n",
    "# Get word vector for a specific word\n",
    "vector = model.wv['good']  # Example: get vector for the word 'good'\n",
    "print(vector)\n",
    "\n",
    "# Convert the entire review into a vector by averaging the word vectors\n",
    "def review_to_vector(review, model):\n",
    "    tokens = tokenize_text(review)\n",
    "    vector = np.zeros(100)  # Assuming vector size of 100\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        vector /= count  # Average the word vectors\n",
    "    return vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "66c698ca-e350-4c63-8d5d-ca75ef6aaebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert training and test data to Word2Vec vectors\n",
    "train_vectors = [review_to_vector(review, model) for review in train_reviews_data]\n",
    "test_vectors = [review_to_vector(review, model) for review in test_reviews_data]\n",
    "\n",
    "# Now you can use these vectors for training your machine learning model\n",
    "# For example, you can use Logistic Regression:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic = LogisticRegression(max_iter=1000)\n",
    "logistic.fit(train_vectors, train_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "64ca6290-44cc-40de-a4c4-075dd622b701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Data: 0.8448575222142785\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = logistic.predict(test_vectors)\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy on Test Data:\", accuracy_score(test_data, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0c8caa91-90a3-4a89-9ecf-230d8880daa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "859c5735-9b0e-4c4e-9f4a-fd82a2cc4769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_model.pkl']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(logistic, \"logistic_model.pkl\")  # Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "833deab3-32d1-4460-b45a-68a91e040ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text=\"love\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d497d05c-2dab-4877-b44a-df22c8706f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype=object)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the input text to a Word2Vec vector\n",
    "input_vector = review_to_vector(input_text, model)\n",
    "        \n",
    "# Predict the sentiment using the trained Logistic Regression model\n",
    "sentiment_pred = logistic.predict([input_vector])\n",
    "sentiment_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6ee6f04d-9131-47c0-ad50-c7e1993a148f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.59785116, -3.28781724, -3.5132947 ,  0.77480167, -1.82307601,\n",
       "       -0.2296907 ,  1.57260501,  2.15844727,  1.49938178, -1.93939281,\n",
       "       -0.67142767, -2.48252225,  1.60396945,  0.66860187,  1.58289254,\n",
       "       -1.06305528, -0.57294446,  2.21171641,  1.01494741,  0.72172928,\n",
       "        2.09183526,  0.64889783, -2.05090547,  0.97738367, -0.39904132,\n",
       "       -0.91435403,  3.14231467, -0.63603473, -1.42310989,  0.52514762,\n",
       "       -0.17155896,  0.52814698,  1.62120986, -2.40355396, -0.85090649,\n",
       "       -0.85478646, -1.0896436 , -2.61618423,  0.76031661, -1.28331494,\n",
       "        2.20182848,  1.85624623,  3.25680184, -2.50924921,  1.95337093,\n",
       "        2.46163607,  0.07102959, -1.78471959, -0.86991316,  0.96741104,\n",
       "       -0.68358713, -0.65544391, -0.73977965,  0.54785687,  0.00428154,\n",
       "       -0.5227778 , -1.99104011,  1.67468679,  0.59779441,  0.98933631,\n",
       "        1.16719484,  0.72363633, -0.21362212, -0.36539251, -3.53378534,\n",
       "        1.50555122,  0.35481757,  0.57384735, -1.15193951,  2.67681456,\n",
       "        1.91582894,  0.55005497,  2.08935046,  0.30233932,  1.76307392,\n",
       "        2.35947156, -1.79551625,  0.22130185, -0.74845195,  0.62997735,\n",
       "        0.14424255,  1.33950424, -0.83601522,  3.81012654,  0.18746954,\n",
       "        0.96054024,  2.18713713,  1.05948353,  2.1003921 , -0.28896067,\n",
       "        0.65892297,  1.13759899,  0.87951636,  0.03818989,  0.43273324,\n",
       "        0.87714517, -1.92482281, -2.05576968,  1.00235283,  0.98708719])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8ebcb476-cbf8-446b-aa39-0d5182ff72b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.8448575222142785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = logistic.predict(test_vectors)\n",
    "print(\"Accuracy on test data:\", accuracy_score(test_data, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eebd10-0d33-47de-a8e6-6e1c312f1f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
